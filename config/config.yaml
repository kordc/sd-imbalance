hydra:
  run:
    dir: . # Use the current working directory for running the job.
  job:
    chdir: False # Do not change the working directory.

# Model selection
model_type: clip # New parameter: Choose 'resnet18' or 'clip'
clip_model_name: openai/clip-vit-base-patch32 # New: Specify CLIP model if model_type is 'clip'

# Oversampling, Undersampling and regularization methods
naive_oversample: false
smote: false
adasyn: false
naive_undersample: false
label_smoothing: false
class_weighting: false

# Wandb
name: base # WANDB run name
project: cifar10_project # WANDB project name

# Project/model settings
epochs: 5
compile: True
batch_size: 256
learning_rate: 0.00001
val_size: 0.2
num_workers: 1
seed: 42
checkpoint_path: # /home/karol/sd-imbalance/fullCIFAR.ckpt
visualize_trained_model: True
freeze_backbone: False # Applies to ResNet (freezes backbone, unfreezes head) or CLIP (freezes whole model)
fine_tune_on_real_data: False
pretrained: False # Applies to ResNet only
finetune_on_checkpoint: False
test_only: false # New flag: If true, only run testing
test_on_real: false # New flag: If true, test_dataloader uses extra_images_dir
test_images_dir: # /home/karol/sd-imbalance/internet_reference

# Dataset settings
# IMPORTANT: These augmentations are primarily for ResNet-style models (32x32).
# For CLIP, your data loading pipeline (e.g., in data.py) must implement
# CLIP-specific transforms (e.g., resize to 224x224 and CLIP's normalization)
# when model_type is 'clip', overriding or supplementing these.
augmentations:
  - name: ToTensor
  - name: RandomCrop
    params:
      size: 32
      padding: 4
  - name: RandomHorizontalFlip
    params:
      p: 0.5
  - name: Resize
    params:
      size: 32
      interpolation: "nearest"
test_augmentations:
  - name: ToTensor
  - name: Resize
    params:
      size: 32
      interpolation: "nearest"
# cutmix_or_mixup: False # Kept commented as per original for ResNet

# Extra images settings
add_extra_images: True
extra_images_dir: /home/karol/sd-imbalance/generated_data/cifar10_synaug_sdxl_class_specific
downsample_classes:
  "airplane": 0.01
  "automobile": 0.01
  "bird": 0.01
  "cat": 0.01
  "deer": 0.01
  "dog": 0.01
  "frog": 0.01
  "horse": 0.01
  "ship": 0.01
  "truck": 0.01
extra_images_per_class:
  "airplane": 4950
  "automobile": 4950
  "bird": 4950
  "cat": 4950
  "deer": 4950
  "dog": 4950
  "frog": 4950
  "horse": 4950
  "ship": 4950
  "truck": 4950
normalize_synthetic: "mean_std" # None, 'mean_std', or 'clahe'
similarity_filter: # None, 'original', or 'synthetic'
similarity_threshold: 0.8 # Threshold for similarity filtering
reference_sample_size: 50 # Number of reference images to use

# Dynamic upsampling via active learning
dynamic_upsample: False
num_dynamic_upsample: 50
dynamic_upsample_target_class: cat