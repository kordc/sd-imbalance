{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f3126a-c3cc-4d99-9df3-44a331552a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: peft in /home/ubuntu/.local/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/.local/lib/python3.10/site-packages (4.49.0)\n",
      "Requirement already satisfied: diffusers in /home/ubuntu/.local/lib/python3.10/site-packages (0.32.2)\n",
      "Requirement already satisfied: accelerate in /home/ubuntu/.local/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/.local/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: ipywidgets in /home/ubuntu/.local/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: safetensors in /home/ubuntu/.local/lib/python3.10/site-packages (from peft) (0.5.2)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from peft) (1.21.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from peft) (0.29.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/lib/python3/dist-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from peft) (21.3)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from peft) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers) (4.6.4)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from diffusers) (9.0.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/lib/python3/dist-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/lib/python3/dist-packages (from ipywidgets) (7.31.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/ubuntu/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/ubuntu/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.25.0->peft) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U peft transformers diffusers accelerate tqdm sentencepiece ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa750465-b17a-4ae2-9ee5-3ca0cd74ad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 18:42:19.346011: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740076939.364181   12330 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740076939.370025   12330 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat breeds: 100\n",
      "Prepositions: 6\n",
      "Objects: 61\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install -U transformers diffusers accelerate tqdm sentencepiece ipywidgets\n",
    "# !huggingface-cli login\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Expanded list of cat breeds\n",
    "cat_breeds = [\n",
    "    \"Abyssinian\",\n",
    "    \"Aegean\",\n",
    "    \"American Bobtail\",\n",
    "    \"American Curl\",\n",
    "    \"American Ringtail\",\n",
    "    \"American Shorthair\",\n",
    "    \"American Wirehair\",\n",
    "    \"Aphrodite Giant\",\n",
    "    \"Arabian Mau\",\n",
    "    \"Asian\",\n",
    "    \"Asian Semi-longhair\",\n",
    "    \"Australian Mist\",\n",
    "    \"Balinese\",\n",
    "    \"Bambino\",\n",
    "    \"Bengal\",\n",
    "    \"Birman\",\n",
    "    \"Bombay\",\n",
    "    \"Brazilian Shorthair\",\n",
    "    \"British Longhair\",\n",
    "    \"British Shorthair\",\n",
    "    \"Burmese\",\n",
    "    \"Burmilla\",\n",
    "    \"California Spangled\",\n",
    "    \"Chantilly-Tiffany\",\n",
    "    \"Chartreux\",\n",
    "    \"Chausie\",\n",
    "    \"Colorpoint Shorthair\",\n",
    "    \"Cornish Rex\",\n",
    "    \"Cymric\",\n",
    "    \"Cyprus\",\n",
    "    \"Devon Rex\",\n",
    "    \"Donskoy\",\n",
    "    \"Dragon Li\",\n",
    "    \"Dwelf\",\n",
    "    \"Egyptian Mau\",\n",
    "    \"European Shorthair\",\n",
    "    \"Exotic Shorthair\",\n",
    "    \"Foldex\",\n",
    "    \"German Rex\",\n",
    "    \"Havana Brown\",\n",
    "    \"Highlander\",\n",
    "    \"Himalayan\",\n",
    "    \"Japanese Bobtail\",\n",
    "    \"Javanese\",\n",
    "    \"Kanaani\",\n",
    "    \"Karelian Bobtail\",\n",
    "    \"Khao Manee\",\n",
    "    \"Kinkalow\",\n",
    "    \"Korat\",\n",
    "    \"Korean Bobtail\",\n",
    "    \"Korn Ja\",\n",
    "    \"Kurilian Bobtail\",\n",
    "    \"Lambkin\",\n",
    "    \"LaPerm\",\n",
    "    \"Lykoi\",\n",
    "    \"Maine Coon\",\n",
    "    \"Manx\",\n",
    "    \"Mekong Bobtail\",\n",
    "    \"Minskin\",\n",
    "    \"Minuet\",\n",
    "    \"Munchkin\",\n",
    "    \"Nebelung\",\n",
    "    \"Neva Masquerade\",\n",
    "    \"Norwegian Forest cat\",\n",
    "    \"Ocicat\",\n",
    "    \"Ojos Azules\",\n",
    "    \"Oriental Bicolor\",\n",
    "    \"Oriental Longhair\",\n",
    "    \"Oriental Shorthair\",\n",
    "    \"Persian\",\n",
    "    \"Peterbald\",\n",
    "    \"Pixie-bob\",\n",
    "    \"Ragamuffin\",\n",
    "    \"Ragdoll\",\n",
    "    \"Raas\",\n",
    "    \"Russian Blue\",\n",
    "    \"Russian White, Russian Black and Russian Tabby\",\n",
    "    \"Sam Sawet\",\n",
    "    \"Savannah\",\n",
    "    \"Scottish Fold\",\n",
    "    \"Selkirk Rex\",\n",
    "    \"Serengeti\",\n",
    "    \"Siamese\",\n",
    "    \"Siberian\",\n",
    "    \"Singapura\",\n",
    "    \"Snowshoe\",\n",
    "    \"Sokoke\",\n",
    "    \"Somali\",\n",
    "    \"Sphynx\",\n",
    "    \"Suphalak\",\n",
    "    \"Thai\",\n",
    "    \"Thai Lilac\",\n",
    "    \"Tonkinese\",\n",
    "    \"Toybob\",\n",
    "    \"Toyger\",\n",
    "    \"Turkish Angora\",\n",
    "    \"Turkish Van\",\n",
    "    \"Turkish Vankedisi\",\n",
    "    \"Ukrainian Levkoy\",\n",
    "    \"York Chocolate\",\n",
    "]\n",
    "\n",
    "print(f\"Cat breeds: {len(cat_breeds)}\")\n",
    "\n",
    "# Expanded list of prepositions\n",
    "prepositions = [\"on\", \"under\", \"next to\", \"beside\", \"in front of\", \"behind\"]\n",
    "\n",
    "# Furniture types that fit with the prepositions\n",
    "furniture_or_outdoor = {\n",
    "    \"on\": [\n",
    "        # Indoor furniture\n",
    "        \"sofa\",\n",
    "        \"armchair\",\n",
    "        \"dining table\",\n",
    "        \"coffee table\",\n",
    "        \"bed\",\n",
    "        \"bookshelf\",\n",
    "        \"cabinet\",\n",
    "        \"cupboard\",\n",
    "        \"chair\",\n",
    "        \"desk\",\n",
    "        \"ottoman\",\n",
    "        \"recliner\",\n",
    "        \"side table\",\n",
    "        \"nightstand\",\n",
    "        \"TV stand\",\n",
    "        \"TV cabinet\",\n",
    "        \"end table\",\n",
    "        \"love seat\",\n",
    "        \"couch\",\n",
    "        \"lounge chair\",\n",
    "        \"bean bag\",\n",
    "        \"bar stool\",\n",
    "        \"console table\",\n",
    "        \"chest of drawers\",\n",
    "        \"vanity\",\n",
    "        \"shelf\",\n",
    "        # Outdoor/natural elements\n",
    "        \"rock\",\n",
    "        \"tree stump\",\n",
    "        \"fence\",\n",
    "        \"bench\",\n",
    "        \"picnic table\",\n",
    "        \"grass\",\n",
    "        \"car hood\",\n",
    "        \"roof\",\n",
    "        \"garden wall\",\n",
    "        \"park bench\",\n",
    "        \"log\",\n",
    "        \"fallen tree\",\n",
    "        \"sand dune\",\n",
    "        \"boulder\",\n",
    "    ],\n",
    "    \"under\": [\n",
    "        # Indoor furniture\n",
    "        \"sofa\",\n",
    "        \"bed\",\n",
    "        \"coffee table\",\n",
    "        \"side table\",\n",
    "        \"desk\",\n",
    "        \"recliner\",\n",
    "        \"nightstand\",\n",
    "        \"chest of drawers\",\n",
    "        \"love seat\",\n",
    "        \"couch\",\n",
    "        \"bookshelf\",\n",
    "        # Outdoor/natural elements\n",
    "        \"tree\",\n",
    "        \"bush\",\n",
    "        \"bridge\",\n",
    "        \"rock\",\n",
    "        \"table\",\n",
    "        \"park bench\",\n",
    "        \"porch\",\n",
    "        \"car\",\n",
    "        \"wooden deck\",\n",
    "        \"fallen tree\",\n",
    "        \"shade\",\n",
    "        \"overhang\",\n",
    "    ],\n",
    "    \"next to\": [\n",
    "        # Indoor furniture\n",
    "        \"sofa\",\n",
    "        \"armchair\",\n",
    "        \"dining table\",\n",
    "        \"coffee table\",\n",
    "        \"bookshelf\",\n",
    "        \"cabinet\",\n",
    "        \"cupboard\",\n",
    "        \"chair\",\n",
    "        \"ottoman\",\n",
    "        \"recliner\",\n",
    "        \"side table\",\n",
    "        \"nightstand\",\n",
    "        \"TV stand\",\n",
    "        \"end table\",\n",
    "        \"love seat\",\n",
    "        \"lounge chair\",\n",
    "        \"console table\",\n",
    "        \"vanity\",\n",
    "        \"window sill\",\n",
    "        # Outdoor/natural elements\n",
    "        \"tree\",\n",
    "        \"bush\",\n",
    "        \"fence\",\n",
    "        \"bench\",\n",
    "        \"log\",\n",
    "        \"rock\",\n",
    "        \"flower bed\",\n",
    "        \"pathway\",\n",
    "        \"pond\",\n",
    "        \"stream\",\n",
    "        \"hill\",\n",
    "        \"park bench\",\n",
    "        \"fire hydrant\",\n",
    "        \"fallen tree\",\n",
    "    ],\n",
    "    \"beside\": [\n",
    "        # Indoor furniture\n",
    "        \"sofa\",\n",
    "        \"armchair\",\n",
    "        \"dining table\",\n",
    "        \"coffee table\",\n",
    "        \"bed\",\n",
    "        \"bookshelf\",\n",
    "        \"chair\",\n",
    "        \"ottoman\",\n",
    "        \"recliner\",\n",
    "        \"side table\",\n",
    "        \"nightstand\",\n",
    "        \"love seat\",\n",
    "        \"couch\",\n",
    "        \"lounge chair\",\n",
    "        \"vanity\",\n",
    "        # Outdoor/natural elements\n",
    "        \"tree\",\n",
    "        \"rock\",\n",
    "        \"bush\",\n",
    "        \"fence\",\n",
    "        \"bench\",\n",
    "        \"stream\",\n",
    "        \"pathway\",\n",
    "        \"log\",\n",
    "        \"garden wall\",\n",
    "        \"pond\",\n",
    "        \"flower bed\",\n",
    "        \"hill\",\n",
    "        \"fallen tree\",\n",
    "    ],\n",
    "    \"in front of\": [\n",
    "        # Indoor furniture\n",
    "        \"sofa\",\n",
    "        \"armchair\",\n",
    "        \"coffee table\",\n",
    "        \"cabinet\",\n",
    "        \"cupboard\",\n",
    "        \"TV stand\",\n",
    "        \"console table\",\n",
    "        \"chest of drawers\",\n",
    "        \"bed\",\n",
    "        \"recliner\",\n",
    "        \"side table\",\n",
    "        \"dining chairs\",\n",
    "        \"love seat\",\n",
    "        # Outdoor/natural elements\n",
    "        \"tree\",\n",
    "        \"rock\",\n",
    "        \"fence\",\n",
    "        \"bush\",\n",
    "        \"bench\",\n",
    "        \"stream\",\n",
    "        \"pathway\",\n",
    "        \"building\",\n",
    "        \"garden wall\",\n",
    "        \"pond\",\n",
    "        \"waterfall\",\n",
    "        \"hill\",\n",
    "        \"statue\",\n",
    "    ],\n",
    "    \"behind\": [\n",
    "        # Indoor furniture\n",
    "        \"sofa\",\n",
    "        \"armchair\",\n",
    "        \"bookshelf\",\n",
    "        \"recliner\",\n",
    "        \"cabinet\",\n",
    "        \"TV stand\",\n",
    "        \"chest of drawers\",\n",
    "        \"love seat\",\n",
    "        # Outdoor/natural elements\n",
    "        \"tree\",\n",
    "        \"bush\",\n",
    "        \"fence\",\n",
    "        \"rock\",\n",
    "        \"log\",\n",
    "        \"bench\",\n",
    "        \"building\",\n",
    "        \"hill\",\n",
    "        \"statue\",\n",
    "        \"garden wall\",\n",
    "        \"shed\",\n",
    "    ],\n",
    "}\n",
    "camera_angles = [\n",
    "    \"a photo taken from above\",\n",
    "    \"a photo taken from below\",\n",
    "    \"a side-view photo\",\n",
    "    \"a front-facing photo\",\n",
    "    \"a photo taken from behind\",\n",
    "]\n",
    "\n",
    "# List of gaze directions\n",
    "gaze_directions = [\n",
    "    \"looking straight ahead\",\n",
    "    \"looking up\",\n",
    "    \"looking down\",\n",
    "    \"looking to the left\",\n",
    "    \"looking to the right\",\n",
    "    \"looking up and to the left\",\n",
    "    \"looking up and to the right\",\n",
    "    \"looking down and to the left\",\n",
    "    \"looking down and to the right\",\n",
    "    \"eyes closed\",\n",
    "    \"looking over its shoulder\",\n",
    "]\n",
    "print(f\"Prepositions: {len(furniture_or_outdoor)}\")\n",
    "print(\n",
    "    f\"Objects: {len(set(list(itertools.chain.from_iterable(furniture_or_outdoor.values()))))}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc17b8f-70e8-41e2-a62e-cae4c8486d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Fix all possible seeds to ensure reproducibility.\n",
    "    :param seed: The seed value to be set for all libraries.\n",
    "    \"\"\"\n",
    "    # Python random module\n",
    "    random.seed(seed)\n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False  # Disables optimizations for reproducibility\n",
    "    # Environment variable for other libraries or hash-based operations\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e15e74c-866f-4de3-b100-737a73cc5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img(folder: str = \"./tmp\", num_inference_steps=4, guidance_scale=0.0):\n",
    "    # Directory to save generated images\n",
    "    output_dir = folder\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    set_seeds(123)\n",
    "    # Generate synthetic images\n",
    "    num_images = 5\n",
    "    for i in tqdm(range(num_images), desc=\"Generating Images\"):\n",
    "        # Randomly select components for the prompt\n",
    "        breed = random.choice(cat_breeds)\n",
    "        preposition = random.choice(prepositions)\n",
    "        furniture = random.choice(furniture_or_outdoor[preposition])\n",
    "        angle = random.choice(camera_angles)\n",
    "        gaze = random.choice(gaze_directions)\n",
    "        if i == 0:\n",
    "            angle = \"a photo taken from behind\"\n",
    "\n",
    "        # Construct the prompt\n",
    "        prompt = (\n",
    "            f\"{angle} of a {breed} cat {preposition} the {furniture}, {gaze}. \"\n",
    "            \"The cat has realistic fur textures, intricate details, and sharp features, \"\n",
    "            \"with soft lighting and a clear focus. The image has a shallow depth of field, \"\n",
    "            \"emphasizing the cat in fine detail. 8k, cinematic, photorealistic\"\n",
    "        )\n",
    "        print(prompt)\n",
    "        pipe.to(torch.bfloat16)\n",
    "\n",
    "        try:\n",
    "            # Generate image\n",
    "            result = pipe(\n",
    "                prompt,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                guidance_scale=guidance_scale,\n",
    "                width=512,\n",
    "                height=512,\n",
    "            )\n",
    "            image = result.images[0]  # Get the first image from the list\n",
    "\n",
    "            # Save the generated image\n",
    "            output_path = os.path.join(\n",
    "                output_dir,\n",
    "                f\"small_{i:05d}_cat_{breed}_{preposition}_{furniture}.png\",\n",
    "            )\n",
    "            image.save(output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate image {i}: {e}\")\n",
    "\n",
    "    print(f\"Generated {num_images} images and saved them in {output_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eedc7e71-6a81-406b-8332-06a7a1e62f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6b979f9b4e4279a647d520a7ff01d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3717b76332074cf8ad2fba24ef3940c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Images:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photo taken from behind of a American Wirehair cat next to the cabinet, looking to the right. The cat has realistic fur textures, intricate details, and sharp features, with soft lighting and a clear focus. The image has a shallow depth of field, emphasizing the cat in fine detail. 8k, cinematic, photorealistic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e241a1cf30545d5ab750a252331bd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Images:  20%|██        | 1/5 [00:01<00:04,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photo taken from behind of a Bambino cat on the vanity, looking down and to the right. The cat has realistic fur textures, intricate details, and sharp features, with soft lighting and a clear focus. The image has a shallow depth of field, emphasizing the cat in fine detail. 8k, cinematic, photorealistic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122f050bfc9849cab9dfded221e038f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Images:  40%|████      | 2/5 [00:01<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photo taken from below of a Japanese Bobtail cat next to the coffee table, looking down. The cat has realistic fur textures, intricate details, and sharp features, with soft lighting and a clear focus. The image has a shallow depth of field, emphasizing the cat in fine detail. 8k, cinematic, photorealistic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f45153abf384674b9bc615ddad5bac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Images:  60%|██████    | 3/5 [00:02<00:01,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photo taken from below of a Javanese cat in front of the side table, looking down. The cat has realistic fur textures, intricate details, and sharp features, with soft lighting and a clear focus. The image has a shallow depth of field, emphasizing the cat in fine detail. 8k, cinematic, photorealistic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af04adb9331444629e494745a4c8c39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Images:  80%|████████  | 4/5 [00:02<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photo taken from above of a Abyssinian cat beside the pond, eyes closed. The cat has realistic fur textures, intricate details, and sharp features, with soft lighting and a clear focus. The image has a shallow depth of field, emphasizing the cat in fine detail. 8k, cinematic, photorealistic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3afac0477fe4268bf360edb8bfa7315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Images: 100%|██████████| 5/5 [00:03<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 images and saved them in stable-diffusion-3.5-large-turbo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-3.5-large-turbo\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "make_img(\"stable-diffusion-3.5-large-turbo\", 4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6e57b-91d6-4d76-9a8d-efd8e4f07a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from diffusers import FluxPipeline\n",
    "\n",
    "# pipe = FluxPipeline.from_pretrained(\n",
    "#     \"black-forest-labs/FLUX.1-schnell\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "# )\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "# make_img(\"FLUX.1-schnell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d288055e-d239-47eb-81c0-83b4f32d963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import FluxPipeline\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-dev\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "make_img(\"FLUX.1-dev\", 50, 3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c22a9-67fc-4185-ae7d-e4dadaf1fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from diffusers import StableDiffusion3Pipeline\n",
    "\n",
    "# pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "#     \"stabilityai/stable-diffusion-3.5-large\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "# )\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "# make_img(\"stable-diffusion-3.5-large\", 28, 3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3bb298-b5c7-421f-95ad-ce2a048105cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from diffusers import StableDiffusion3Pipeline\n",
    "\n",
    "# pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "#     \"stabilityai/stable-diffusion-3.5-medium\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "# )\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# make_img(\"stable-diffusion-3.5-medium\", 40, 4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f9ac8-ebab-4d00-b56c-9b1a5f15af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from diffusers import StableDiffusion3Pipeline\n",
    "\n",
    "# pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "#     \"stabilityai/stable-diffusion-3-medium-diffusers\",\n",
    "#     torch_dtype=torch.float16,\n",
    "# )\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# make_img(\"stable-diffusion-3-medium-diffusers\", 28, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fed9e8-fb70-4c82-b512-25f2ffa60868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = DiffusionPipeline.from_pretrained(\n",
    "#     \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     use_safetensors=True,\n",
    "#     variant=\"fp16\",\n",
    "# )\n",
    "# pipe.to(\"cuda\")\n",
    "# make_img(\"stable-diffusion-xl-base-1.0\", 28, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839c219-3486-4e4e-9615-5cbc8266e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from diffusers import AutoPipelineForText2Image\n",
    "\n",
    "# pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "#     \"stabilityai/sdxl-turbo\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     variant=\"fp16\",\n",
    "# )\n",
    "# pipe.to(\"cuda\")\n",
    "\n",
    "# make_img(\"sdxl-turbo\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e585031-d6de-4e89-b5b3-db87029aef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from diffusers import DiffusionPipeline\n",
    "# import torch\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model_repo_id = \"stabilityai/stable-diffusion-3.5-large-turbo\"\n",
    "\n",
    "# torch_dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# pipe = DiffusionPipeline.from_pretrained(model_repo_id, torch_dtype=torch_dtype)\n",
    "# pipe = pipe.to(device)\n",
    "\n",
    "# pipe.load_lora_weights(\"prithivMLmods/SD3.5-Large-Turbo-HyperRealistic-LoRA\", weight_name=\"SD3.5-4Step-Large-Turbo-HyperRealistic-LoRA.safetensors\")\n",
    "# trigger_word = \"hyper realistic\"  # Specify trigger word for LoRA\n",
    "# pipe.fuse_lora(lora_scale=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1857e-f758-428b-bdb6-e4113dc5034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_img(\"real\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a380d1-3514-46fe-b91e-13cf67debf30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
